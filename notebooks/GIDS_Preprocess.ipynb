{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from names_dataset import NameDataset\n",
    "import cleanup_utils\n",
    "\n",
    "# pd.set_option('max_colwidth', None)\n",
    "nd = NameDataset()\n",
    "first_names = nd.first_names\n",
    "last_names = nd.last_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = '/data/NLP/GIDS (Google IISc Distant Supervision)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_tokens(token: str, ner: str):\n",
    "    pronouns = [\"I\",\"you\",\"he\",\"she\",\"me\",\"you\",\"him\",\"her\",\"mine\",\"yours\",\"his\",\"hers\",\"myself\",\"yourself\",\"himself\",\"herself\"]\n",
    "    schools = ['College', 'University', 'School']\n",
    "    locations = ['Square', 'County', 'Beach', 'Chicago', 'City', 'Island']\n",
    "    entities = [*schools, *locations,  'Agr']\n",
    "    if '_' in token:\n",
    "        if token == '_':\n",
    "            ner = 'O'\n",
    "        else:\n",
    "            # if len(word.split('_')) > 1:\n",
    "            splitted = token.split('_')\n",
    "            if splitted[0] in first_names and splitted[1] in last_names and min([entity.lower() not in token.lower() for entity in entities]):\n",
    "                ner = 'PERSON'\n",
    "            if max([location.lower() in token.lower() for location in locations]) and not max([school.lower() in token.lower() for school in schools]):\n",
    "                ner = \"LOCATION\"\n",
    "            if max([school.lower() in token.lower() for school in schools]):\n",
    "                ner = \"ORGANIZATION\"\n",
    "    ner = 'PERSON' if token.lower() in pronouns else ner\n",
    "    return token, ner\n",
    "\n",
    "def load_gids_dataset(path: str):\n",
    "    data = []\n",
    "\n",
    "    with open(path) as file:\n",
    "        for line in file:\n",
    "            tmp = {'relations': []}\n",
    "\n",
    "            loaded_data = json.loads(line)\n",
    "            corenlp = loaded_data.get('corenlp', {}) if loaded_data.get('corenlp', {}) is not None else {}\n",
    "            sentences = corenlp.get('sentences', [])\n",
    "\n",
    "            for index, sentence in enumerate(sentences):\n",
    "                sentence_relations = sentence.get('openie')\n",
    "\n",
    "                for tmp_relation in sentence_relations:\n",
    "                    tmp_relation['tokens'] = []\n",
    "                    tmp_relation['labels'] = []\n",
    "\n",
    "                    for token_metadata in sentence.get('tokens', []):\n",
    "                        token, ner = fix_tokens(token_metadata.get('originalText'), token_metadata.get('ner'))\n",
    "                        splitted_token = token.split('_')\n",
    "                        token = ' '.join(splitted_token)\n",
    "                        if token != '_':\n",
    "                            tmp_relation['tokens'].extend(splitted_token)\n",
    "                            tmp_relation['labels'].extend([*[ner]*len(splitted_token)])\n",
    "\n",
    "                tmp['relations'].append(sentence_relations)\n",
    "\n",
    "            data.append(tmp)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for _dir in os.listdir(f'{ROOT_PATH}/raw/'):\n",
    "    data = load_gids_dataset(f'/data/NLP/GIDS (Google IISc Distant Supervision)/raw/{_dir}')\n",
    "\n",
    "    df = (\n",
    "        pd.DataFrame(data)\n",
    "        .explode(\"relations\")\n",
    "        .explode(\"relations\")\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        df\n",
    "        .assign(**df[\"relations\"].apply(pd.Series))\n",
    "        .drop(columns=['relations','objectSpan','subjectSpan','relationSpan'])\n",
    "        # .assign(index = df.reset_index().index)\n",
    "    )\n",
    "\n",
    "    df = df.assign(labels=df['labels'].apply(cleanup_utils.process_labels))\n",
    "    df = df.assign(object=df['object'].apply(lambda x: x[1:].replace('_', ' ') if x.startswith('_') else x.replace('_', ' ')))\n",
    "    df = df.assign(subject=df['subject'].apply(lambda x: x[1:].replace('_', ' ') if x.startswith('_') else x.replace('_', ' ')))\n",
    "\n",
    "    df.reset_index(drop=True).to_json(f'{ROOT_PATH}/preprocessed/{_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(f\"{ROOT_PATH}/preprocessed/train.json\").reset_index(drop=True)\n",
    "dev_df = pd.read_json(f\"{ROOT_PATH}/preprocessed/dev.json\").reset_index(drop=True)\n",
    "test_df = pd.read_json(f\"{ROOT_PATH}/preprocessed/test.json\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered = (\n",
    "#     dev_df\n",
    "#     .loc[:,['relation','objectSpan','subjectSpan','relationSpan','subject','object','tokens','labels']]\n",
    "# )\n",
    "\n",
    "# df_filtered.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "414129bc5f9fadc6aae6e1926404349d54c672fb6156a1a65104540d3f3f309d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
