{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from modeling_classes import CustomBertForTokenClassification, CustomDataset\n",
    "import training\n",
    "import utils\n",
    "from utils import Config\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = os.path.dirname(os.path.abspath(\"!pwd\"))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LABELS_TO_IDS, IDS_TO_LABELS = utils.load_labels()\n",
    "SWEEP_CONFIG = utils.load_config(Config.SWEEP_CONFIG)\n",
    "CONFIG = utils.load_config(Config.CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    return [item for item in IDS_TO_LABELS.values()]\n",
    "\n",
    "\n",
    "def get_data_loaders(only_ner=True):\n",
    "    train_dataset = pd.read_json(f\"{wandb.config['dataset_path']}train.json\").reset_index(drop=True)\n",
    "    dev_dataset = pd.read_json(f\"{wandb.config['dataset_path']}dev.json\").reset_index(drop=True)\n",
    "    test_dataset = pd.read_json(f\"{wandb.config['dataset_path']}test.json\").reset_index(drop=True)\n",
    "\n",
    "    if only_ner:\n",
    "        train_dataset = utils.prepare(train_dataset)\n",
    "        dev_dataset = utils.prepare(dev_dataset)\n",
    "        test_dataset = utils.prepare(test_dataset)\n",
    "\n",
    "    train_loader = DataLoader(CustomDataset(train_dataset, DEVICE), batch_size=wandb.config[\"batch_size\"], shuffle=True)\n",
    "    dev_loader = DataLoader(CustomDataset(dev_dataset, DEVICE), batch_size=wandb.config[\"batch_size\"], shuffle=True)\n",
    "    test_loader = DataLoader(CustomDataset(test_dataset, DEVICE), batch_size=wandb.config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    return train_loader, dev_loader, test_loader\n",
    "\n",
    "\n",
    "def get_optimizer(model):\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=wandb.config[\"learning_rate\"], weight_decay=wandb.config[\"weight_decay\"])\n",
    "    if wandb.config['optimizer'] == 'ADAM':\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=wandb.config[\"learning_rate\"], weight_decay=wandb.config[\"weight_decay\"])\n",
    "    if wandb.config['optimizer'] == 'ADAMW':\n",
    "        optimizer = torch.optim.AdamW(params=model.parameters(), lr=wandb.config[\"learning_rate\"], weight_decay=wandb.config[\"weight_decay\"])\n",
    "    if wandb.config['optimizer'] == 'SGD':\n",
    "        optimizer = torch.optim.SGD(params=model.parameters(), lr=wandb.config[\"learning_rate\"], weight_decay=wandb.config[\"weight_decay\"], momentum=0.9) # noqa\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def resume_state(model, optimizer, scheduler, metrics, model_version: str='latest', config_version: str='latest', config_overwrites: Dict[str, str]={}):\n",
    "    artifact = wandb.run.use_artifact(f'kripso/{wandb.config[\"project_name\"]}/{wandb.config[\"model\"]}:{model_version}', type='model')\n",
    "    artifact.download(f'{CURRENT_DIR}/models/')\n",
    "    artifact = wandb.run.use_artifact(f'kripso/{wandb.config[\"project_name\"]}/config:{config_version}', type='config')\n",
    "    artifact.download(f'{CURRENT_DIR}/conf/')\n",
    "    wandb.config = {**utils.load_config(Config.BACKUP), **config_overwrites}\n",
    "\n",
    "    checkpoint = torch.load(f'{CURRENT_DIR}/models/{wandb.config[\"model\"]}.pt')\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    metrics = checkpoint['metrics']\n",
    "    metrics['step'] -= 1\n",
    "\n",
    "    return model, optimizer, scheduler, metrics\n",
    "\n",
    "\n",
    "@utils.wandb_init(CONFIG)\n",
    "def main(resume: bool=False, *args, **kwargs):\n",
    "    model = CustomBertForTokenClassification(labels=get_labels()).to(DEVICE)\n",
    "    optimizer = get_optimizer(model)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=wandb.config[\"scheduler_step_size\"], gamma=wandb.config[\"scheduler_gamma\"])\n",
    "    metrics = {\"loss\": 0, \"accuracy\": 0, \"f1_score\": 0, \"index\": 1, \"step\": 0}\n",
    "\n",
    "    if resume:\n",
    "        model, optimizer, scheduler, metrics = resume_state(model, optimizer, scheduler, metrics, *args, **kwargs)\n",
    "\n",
    "    train_loader, dev_loader, test_loader = get_data_loaders(True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    return training.fit(model, optimizer, scheduler, metrics, train_loader, dev_loader, test_loader, DEVICE)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sweep_id = wandb.sweep(sweep=SWEEP_CONFIG, project=CONFIG['project_name'])\n",
    "# wandb.agent(sweep_id, function=main, count=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(resume=True, model_version='v31',config_overwrites=CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "414129bc5f9fadc6aae6e1926404349d54c672fb6156a1a65104540d3f3f309d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
